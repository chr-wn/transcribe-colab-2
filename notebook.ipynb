{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKsqtZQJKCmj"
      },
      "source": [
        "# Audio Transcription Tool - Google Colab (GPU Accelerated)\n",
        "\n",
        "This notebook demonstrates how to use the GPU-accelerated audio transcription tool in Google Colab.\n",
        "\n",
        "**Important:** Make sure you're using a GPU runtime!\n",
        "- Go to Runtime → Change runtime type → Hardware accelerator → GPU (T4 or A100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN-2jzt3KCml",
        "outputId": "4049fb61-5efd-4742-d266-5266a365a002"
      },
      "outputs": [],
      "source": [
        "# Clone the repository\n",
        "!rm -rf repo\n",
        "!git clone https://github.com/chr-wn/transcribe-colab-2.git repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6j5Be3gKCml",
        "outputId": "89cf93dc-b3d3-4629-c22d-408c1a3d8927"
      },
      "outputs": [],
      "source": [
        "# Run the GPU-optimized Colab setup script\n",
        "%cd /content/repo\n",
        "!chmod +x colab_setup.sh\n",
        "!./colab_setup.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pIdN9gmKCml"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# # Upload audio files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# # List uploaded files\n",
        "# for filename in uploaded.keys():\n",
        "#     print(f\"Uploaded: {filename} ({len(uploaded[filename])} bytes)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B1zRs77KUjB",
        "outputId": "9c60cc4c-5487-4920-bbd5-50620735065e"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!ls /content/drive/MyDrive/pows/\n",
        "!ls \"/content/drive/MyDrive/pows/01-1-pows.mp3\"\n",
        "filename=\"/content/drive/MyDrive/pows/01-1-pows.mp3\"\n",
        "print(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EoF7D75smuvF",
        "outputId": "a9eb052b-eb20-4b9f-868f-f7d82e2a29a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "usage: whisper.cpp/build/bin/whisper-cli [options] file0 file1 ...\n",
            "supported audio formats: flac, mp3, ogg, wav\n",
            "\n",
            "options:\n",
            "  -h,        --help              [default] show this help message and exit\n",
            "  -t N,      --threads N         [2      ] number of threads to use during computation\n",
            "  -p N,      --processors N      [1      ] number of processors to use during computation\n",
            "  -ot N,     --offset-t N        [0      ] time offset in milliseconds\n",
            "  -on N,     --offset-n N        [0      ] segment index offset\n",
            "  -d  N,     --duration N        [0      ] duration of audio to process in milliseconds\n",
            "  -mc N,     --max-context N     [-1     ] maximum number of text context tokens to store\n",
            "  -ml N,     --max-len N         [0      ] maximum segment length in characters\n",
            "  -sow,      --split-on-word     [false  ] split on word rather than on token\n",
            "  -bo N,     --best-of N         [5      ] number of best candidates to keep\n",
            "  -bs N,     --beam-size N       [5      ] beam size for beam search\n",
            "  -ac N,     --audio-ctx N       [0      ] audio context size (0 - all)\n",
            "  -wt N,     --word-thold N      [0.01   ] word timestamp probability threshold\n",
            "  -et N,     --entropy-thold N   [2.40   ] entropy threshold for decoder fail\n",
            "  -lpt N,    --logprob-thold N   [-1.00  ] log probability threshold for decoder fail\n",
            "  -nth N,    --no-speech-thold N [0.60   ] no speech threshold\n",
            "  -tp,       --temperature N     [0.00   ] The sampling temperature, between 0 and 1\n",
            "  -tpi,      --temperature-inc N [0.20   ] The increment of temperature, between 0 and 1\n",
            "  -debug,    --debug-mode        [false  ] enable debug mode (eg. dump log_mel)\n",
            "  -tr,       --translate         [false  ] translate from source language to english\n",
            "  -di,       --diarize           [false  ] stereo audio diarization\n",
            "  -tdrz,     --tinydiarize       [false  ] enable tinydiarize (requires a tdrz model)\n",
            "  -nf,       --no-fallback       [false  ] do not use temperature fallback while decoding\n",
            "  -otxt,     --output-txt        [false  ] output result in a text file\n",
            "  -ovtt,     --output-vtt        [false  ] output result in a vtt file\n",
            "  -osrt,     --output-srt        [false  ] output result in a srt file\n",
            "  -olrc,     --output-lrc        [false  ] output result in a lrc file\n",
            "  -owts,     --output-words      [false  ] output script for generating karaoke video\n",
            "  -fp,       --font-path         [/System/Library/Fonts/Supplemental/Courier New Bold.ttf] path to a monospace font for karaoke video\n",
            "  -ocsv,     --output-csv        [false  ] output result in a CSV file\n",
            "  -oj,       --output-json       [false  ] output result in a JSON file\n",
            "  -ojf,      --output-json-full  [false  ] include more information in the JSON file\n",
            "  -of FNAME, --output-file FNAME [       ] output file path (without file extension)\n",
            "  -np,       --no-prints         [false  ] do not print anything other than the results\n",
            "  -ps,       --print-special     [false  ] print special tokens\n",
            "  -pc,       --print-colors      [false  ] print colors\n",
            "             --print-confidence  [false  ] print confidence\n",
            "  -pp,       --print-progress    [false  ] print progress\n",
            "  -nt,       --no-timestamps     [false  ] do not print timestamps\n",
            "  -l LANG,   --language LANG     [en     ] spoken language ('auto' for auto-detect)\n",
            "  -dl,       --detect-language   [false  ] exit after automatically detecting language\n",
            "             --prompt PROMPT     [       ] initial prompt (max n_text_ctx/2 tokens)\n",
            "  -m FNAME,  --model FNAME       [models/ggml-base.en.bin] model path\n",
            "  -f FNAME,  --file FNAME        [       ] input audio file path\n",
            "  -oved D,   --ov-e-device DNAME [CPU    ] the OpenVINO device used for encode inference\n",
            "  -dtw MODEL --dtw MODEL         [       ] compute token-level timestamps\n",
            "  -ls,       --log-score         [false  ] log best decoder scores of tokens\n",
            "  -ng,       --no-gpu            [false  ] disable GPU\n",
            "  -fa,       --flash-attn        [false  ] flash attention\n",
            "  -sns,      --suppress-nst      [false  ] suppress non-speech tokens\n",
            "  --suppress-regex REGEX         [       ] regular expression matching tokens to suppress\n",
            "  --grammar GRAMMAR              [       ] GBNF grammar to guide decoding\n",
            "  --grammar-rule RULE            [       ] top-level GBNF grammar rule name\n",
            "  --grammar-penalty N            [100.0  ] scales down logits of nongrammar tokens\n",
            "\n",
            "Voice Activity Detection (VAD) options:\n",
            "             --vad                           [false  ] enable Voice Activity Detection (VAD)\n",
            "  -vm FNAME, --vad-model FNAME               [       ] VAD model path\n",
            "  -vt N,     --vad-threshold N               [0.50   ] VAD threshold for speech recognition\n",
            "  -vspd N,   --vad-min-speech-duration-ms  N [250    ] VAD min speech duration (0.0-1.0)\n",
            "  -vsd N,    --vad-min-silence-duration-ms N [100    ] VAD min silence duration (to split segments)\n",
            "  -vmsd N,   --vad-max-speech-duration-s   N [FLT_MAX] VAD max speech duration (auto-split longer)\n",
            "  -vp N,     --vad-speech-pad-ms           N [30     ] VAD speech padding (extend segments)\n",
            "  -vo N,     --vad-samples-overlap         N [0.10   ] VAD samples overlap (seconds between segments)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!whisper.cpp/build/bin/whisper-cli -h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W_Ape634yTZ",
        "outputId": "6ed5cdf8-7176-42ab-8ca9-65a58e7b4553"
      },
      "outputs": [],
      "source": [
        "# usage: transcribe.py [-h] [-m {tiny,base,small,medium,large}] [-o OUTPUT] [-t]\n",
        "#                      [-b] [-v]\n",
        "#                      files [files ...]\n",
        "\n",
        "# Convert audio files to text transcripts using whisper.cpp\n",
        "\n",
        "# positional arguments:\n",
        "#   files                 Audio file(s) to transcribe\n",
        "\n",
        "# options:\n",
        "#   -h, --help            show this help message and exit\n",
        "#   -m {tiny,base,small,medium,large}, --model {tiny,base,small,medium,large}\n",
        "#                         Whisper model to use (default: base)\n",
        "#   -o OUTPUT, --output OUTPUT\n",
        "#                         Output filename (default: replace extension with .txt)\n",
        "#   -t, --timestamps      Include timestamps in output\n",
        "#   -b, --batch           Batch mode: concatenate multiple files into single\n",
        "#                         output\n",
        "#   -v, --verbose         Show detailed information\n",
        "\n",
        "# Examples:\n",
        "#   transcribe.py audio.mp3                    # Basic transcription\n",
        "#   transcribe.py -m large audio.mp3           # Use large model\n",
        "#   transcribe.py -t audio.mp3                 # Include timestamps\n",
        "#   transcribe.py -o transcript.txt audio.mp3  # Custom output filename\n",
        "#   transcribe.py *.mp3                        # Batch process multiple files\n",
        "#   transcribe.py -b -o all.txt *.mp3          # Concatenate all into single file\n",
        "#   transcribe.py -v audio.mp3                 # Verbose output\n",
        "\n",
        "# Supported Models:\n",
        "#   tiny   - Fastest, least accurate (~39MB)\n",
        "#   base   - Good balance (default) (~74MB)\n",
        "#   small  - Better accuracy (~244MB)\n",
        "#   medium - High accuracy (~769MB)\n",
        "#   large  - Best accuracy (~1550MB)\n",
        "\n",
        "mp3_files = [\n",
        "  '01-1-pows',\n",
        "  '02-1-pows-p1-7',\n",
        "  '03-1-pows-p8-17',\n",
        "  '04-1-pows-p18-41',\n",
        "  '05-1-pows-p42-56',\n",
        "  '06-2-pows-p57-74',\n",
        "  '07-2-pows-p75-90',\n",
        "  '08-2-pows-p91-134',\n",
        "  '09-3-pows-p135-146',\n",
        "  '10-3-pows-p147-158',\n",
        "  '11-3-pows-p159-163',\n",
        "  '12-3-pows-p164-184',\n",
        "  '13-4-pows-p185-190',\n",
        "  '14-4-pows-p191-197',\n",
        "  '15-4-pows-p197-200',\n",
        "  '16-4-pows-p201-206',\n",
        "  '17-5-pows-p207-213',\n",
        "  '18-5-pows-p214-222',\n",
        "  '19-5-pows-p223-232'\n",
        "]\n",
        "\n",
        "for filename in mp3_files:\n",
        "  !./transcribe.py -v -m medium \"/content/drive/MyDrive/pows/{filename}.mp3\"\n",
        "  print(\"\\n\"*5)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
