{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Transcription Tool - Google Colab (GPU Accelerated)\n",
    "\n",
    "This notebook demonstrates how to use the GPU-accelerated audio transcription tool in Google Colab.\n",
    "\n",
    "**Important:** Make sure you're using a GPU runtime!\n",
    "- Go to Runtime → Change runtime type → Hardware accelerator → GPU (T4 or A100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GPU Availability\n",
    "\n",
    "First, let's verify we have GPU access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "print(\"\\nIf you see GPU information above, you're ready for fast transcription!\")\n",
    "print(\"If not, go to Runtime → Change runtime type → Hardware accelerator → GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Clone the repository and run the GPU-optimized setup script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/your-username/your-repo.git\n",
    "%cd your-repo/repo-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the GPU-optimized Colab setup script\n",
    "!chmod +x colab_setup.sh\n",
    "!./colab_setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Setup\n",
    "\n",
    "Verify everything is working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the setup\n",
    "!python test_setup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Audio Files\n",
    "\n",
    "Use the file browser on the left to upload your audio files, or use the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Upload audio files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# List uploaded files\n",
    "for filename in uploaded.keys():\n",
    "    print(f\"Uploaded: {filename} ({len(uploaded[filename])} bytes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Transcription\n",
    "\n",
    "Transcribe an audio file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'audio.mp3' with your actual filename\n",
    "!./transcribe.py audio.mp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcription with Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe with timestamps\n",
    "!./transcribe.py -t audio.mp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU-Accelerated Models\n",
    "\n",
    "With GPU acceleration, you can use larger models for much better accuracy without significant speed penalty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the large model - much faster with GPU!\n",
    "!./transcribe.py -m large -v audio.mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare speeds: small vs large model\n",
    "import time\n",
    "\n",
    "print(\"Testing small model...\")\n",
    "start = time.time()\n",
    "!./transcribe.py -m small audio.mp3\n",
    "small_time = time.time() - start\n",
    "\n",
    "print(f\"\\nSmall model took: {small_time:.1f} seconds\")\n",
    "\n",
    "print(\"\\nTesting large model...\")\n",
    "start = time.time()\n",
    "!./transcribe.py -m large audio.mp3\n",
    "large_time = time.time() - start\n",
    "\n",
    "print(f\"\\nLarge model took: {large_time:.1f} seconds\")\n",
    "print(f\"Large model is only {large_time/small_time:.1f}x slower but much more accurate!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process multiple files and concatenate into one output\n",
    "!./transcribe.py -b -o combined_transcript.txt *.mp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Results\n",
    "\n",
    "Display the transcription results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List generated transcript files\n",
    "!ls -la *.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a transcript file (replace with your actual filename)\n",
    "with open('audio.txt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Benchmark\n",
    "\n",
    "Let's benchmark the GPU acceleration performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance benchmark\n",
    "import time\n",
    "import os\n",
    "\n",
    "def benchmark_model(model_name, audio_file):\n",
    "    \"\"\"Benchmark transcription speed for a given model.\"\"\"\n",
    "    if not os.path.exists(audio_file):\n",
    "        print(f\"Audio file {audio_file} not found. Please upload an audio file first.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Benchmarking {model_name} model...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Run transcription\n",
    "    !./transcribe.py -m {model_name} -v {audio_file}\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(f\"{model_name} model completed in {duration:.1f} seconds\")\n",
    "    return duration\n",
    "\n",
    "# Benchmark different models (replace 'audio.mp3' with your file)\n",
    "audio_file = 'audio.mp3'  # Change this to your uploaded file\n",
    "\n",
    "if os.path.exists(audio_file):\n",
    "    models = ['tiny', 'base', 'small', 'medium', 'large']\n",
    "    times = {}\n",
    "    \n",
    "    for model in models:\n",
    "        times[model] = benchmark_model(model, audio_file)\n",
    "        print()\n",
    "    \n",
    "    # Show results\n",
    "    print(\"=== BENCHMARK RESULTS ===\")\n",
    "    for model, duration in times.items():\n",
    "        if duration:\n",
    "            print(f\"{model:8s}: {duration:6.1f}s\")\n",
    "else:\n",
    "    print(\"Please upload an audio file first to run the benchmark.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Memory Usage\n",
    "\n",
    "Monitor GPU memory usage during transcription:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU memory usage\n",
    "!nvidia-smi --query-gpu=memory.used,memory.total --format=csv,noheader,nounits\n",
    "\n",
    "print(\"\\nRunning transcription with large model...\")\n",
    "!./transcribe.py -m large audio.mp3\n",
    "\n",
    "print(\"\\nGPU memory after transcription:\")\n",
    "!nvidia-smi --query-gpu=memory.used,memory.total --format=csv,noheader,nounits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Results\n",
    "\n",
    "Download the transcript files to your computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import glob\n",
    "\n",
    "# Download all transcript files\n",
    "for txt_file in glob.glob('*.txt'):\n",
    "    files.download(txt_file)\n",
    "    print(f\"Downloaded: {txt_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}